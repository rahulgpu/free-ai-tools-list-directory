<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Is This Image NSFW - AI Tool</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 40px;
        }
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
        }
        .bio {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 20px;
        }
        .button {
            display: inline-block;
            background-color: #007bff;
            color: white;
            padding: 15px 30px;
            text-decoration: none;
            border-radius: 5px;
            font-weight: bold;
            font-size: 1.1rem;
            transition: background-color 0.3s;
        }
        .button:hover {
            background-color: #0056b3;
        }
        .content {
            background: #f9f9f9;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
        }
        .meta {
            margin-top: 20px;
            font-size: 0.9rem;
            color: #888;
        }
    </style>
</head>
<body>
    <header>
        <img src="https://media.theresanaiforthat.com/assets/favicon-large.svg?width=100" alt="Is This Image NSFW Logo" style="width: auto; height: 100px; margin-bottom: 20px;">
        <h1>Is This Image NSFW</h1>
        <p class="bio">An extremely fast NSFW image filter, powered by open-source models.</p>
        <a href="https://aitoolslist.xyz/is-this-image-nsfw/" class="button">Visit Tool Page</a>
    </header>

    <main>
        <div class="content">
            <h2>About Is This Image NSFW</h2>
            <p>Is This Image NSFW? is an AI-powered tool designed to filter and identify NSFW (not safe for work) content in images. It employs machine learning and leverages open-source models to carry out its task. Despite the name, its use is not just limited to deciphering if an image is safe for work or not; the tool also analyses and distinguishes between arbitrary images. Users can easily upload PNG or JPG files with a simple drag-and-drop action, providing a seamless and user-friendly experience. Although the built-in safety checker's documentation is noted as lacking, adjustments can be made to use it with diverse images besides the AI-generated ones. Developed by @m1guelpf, this tool represents an application of AI in image analysis and content moderation, potentially aiding in the regulation and safe-keeping of digital content within both professional and personal environments.</p>
        </div>

        <div class="meta">
            <p>Category: NSFW image detection</p>
        </div>
    </main>
</body>
</html>