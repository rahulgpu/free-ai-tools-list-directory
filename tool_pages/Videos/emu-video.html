<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emu Video - AI Tool</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 40px;
        }
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
        }
        .bio {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 20px;
        }
        .button {
            display: inline-block;
            background-color: #007bff;
            color: white;
            padding: 15px 30px;
            text-decoration: none;
            border-radius: 5px;
            font-weight: bold;
            font-size: 1.1rem;
            transition: background-color 0.3s;
        }
        .button:hover {
            background-color: #0056b3;
        }
        .content {
            background: #f9f9f9;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
        }
        .meta {
            margin-top: 20px;
            font-size: 0.9rem;
            color: #888;
        }
    </style>
</head>
<body>
    <header>
        <img src="https://media.theresanaiforthat.com/icons/emu-video.svg?width=100" alt="Emu Video Logo" style="width: auto; height: 100px; margin-bottom: 20px;">
        <h1>Emu Video</h1>
        <p class="bio">Video generation from text prompts</p>
        <a href="https://aitoolslist.xyz/emu-video/" class="button">Visit Tool Page</a>
    </header>

    <main>
        <div class="content">
            <h2>About Emu Video</h2>
            <p>Emu Video is a tool that focuses on text-to-video generation using explicit image conditioning. It employs diffusion models to factorize the generation process into two steps: generating an image based on a text prompt and then generating a video based on the prompt and the generated image. This factorized approach enables efficient training of high-quality video generation models. Emu Video stands out from previous methods that require a deep cascade of models by only needing two diffusion models to generate 512px, 4-second-long videos at 16fps.The tool provides state-of-the-art results in text-to-video generation when compared to other models such as Make-a-Video (MAV), Imagen-Video (IMAGEN), Align Your Latents (AYL), Reuse & Diffuse (R&D), Cog Video (COG), Gen2 (GEN2), and Pika Labs (PIKA). Human raters have selected Emu Video's 512 pixels, 16 frames per second, 4-second-long videos as the most convincing ones in terms of quality and faithfulness to the given prompt.Authors of this tool include Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai Saketh Rambhatla, Akbar Shah, Xi Yin, Devi Parikh, and Ishan Misra, with equal technical contributions coming from Rohit Girdhar and Mannat Singh. The tool acknowledges the support of multiple collaborators who assisted in the work, providing data and infrastructure. Emu Video also maintains privacy and cookie policies, which can be viewed on their website.</p>
        </div>

        <div class="meta">
            <p>Category: Videos</p>
        </div>
    </main>
</body>
</html>